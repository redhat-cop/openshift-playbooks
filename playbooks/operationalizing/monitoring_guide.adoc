---
---
= Monitoring OpenShift
Eric Sauer <esauer@redhat.com>
v1.0, 2017-08-29
:scripts_repo: https://github.com/redhat-cop/openshift-toolkit
:toc: macro
:toc-title:

OpenShift Monitoring is an ever evolving problem space, with many layers, approaches, and complexities. We attempt to unpack them here.

include::../../_includes/variables.adoc[]
toc::[]

== Overview

NOTE: Before reading this guide, we recommend first reading link:/playbooks/installation/admin_overview.html[An Overview of OpenShift for System Admins].

The following document intends to provide starting guidance on how to build a monitoring approach for OpenShift. In it, we will present a suggested categorization of _checks_ that would form the basis for items that should usually generate an alert of some kind in a production cluster.

This document will not propose any specific tooling for a monitoring approach, but instead presents the data points that are believed to be important when designing a cluster monitoring approach and provides examples of the logic involved in creating alerts.

NOTE: Discussion of tooling and building a monitoring stack implementation will be discussed in a future guide.

Each section below will present a table of data, giving a description of the data point, and a sample command that might trigger an alert.

== Ensuring a cluster is healthy

=== Docker

Docker is an essential component of an OpenShift environment. The overall health of docker on each master and node instance ensures stability within an OpenShift cluster. The following components are areas that should be monitored on each node.

.Docker checks
[width="100%",cols="3,6,10",options="header"]
|=========================================================
|Check Name |Description |Sample Alerting Logic

|Docker Daemon |Check that docker is running on a system | `systemctl is-active docker`

|Docker Storage|Check that docker's storage has adequate space | `echo $(echo \"$(docker info 2>/dev/null  &#124; awk '/Data Space Available/ {print $4}') / $(docker info 2>/dev/null  &#124; awk '/Data Space Total/ {print $4}')\"  &#124; bc -l) '>' 0.3  &#124; bc -l`

|Docker Metadata Storage |Check that docker's metadata storage volume is not full | `echo $(echo \"$(docker info 2>/dev/null  &#124; awk '/Metadata Space Available/ {print $4}') / $(docker info 2>/dev/null  &#124; awk '/Metadata Space Total/ {print $4}')\"  &#124; bc -l) '>' 0.3  &#124; bc -l`

|=========================================================

=== Nodes & Masters

.Node,Master checks
[width="100%",cols="15%,30%,10%,5%,40%",options="header"]
|===
| Check Name | Description | Relevant Hosts | OCP Version | Sample Alerting Logic
.2+|Etcd Service .2+|Check that etcd is active .2+|Masters | \<= 3.9 | `systemctl is-active etcd`| >= 3.10 | `oc get pods -n kube-system --no-headers -o=custom-columns=POD:.metadata.name,STATUS:.status.phase &#124; grep -i "master-etcd" &#124; grep -i "running" &#124;  if [ $( wc -l) -eq 3 ]; then exit 0; else exit 1; fi`

.2+|Etcd Storage .2+|Check that the etcd volume is not too full .2+|Masters | \<= 3.9 | `echo "$(lvs &#124; awk '/etcd/ {print $5}') > 70" &#124; bc` | >= 3.10 | `echo "$(lvs &#124; awk '/etcd/ {print $5}') > 70" &#124; bc`

.2+|Master API Service (single master) .2+|Check that the Master API Service or pods are active .2+|Masters | \<= 3.9 | `systemctl is-active atomic-openshift-master`| >= 3.10 | Same as multi-master check.

.2+|Master API Service (multi-master) .2+|Check that the Master API Service or pods are active .2+|Masters |  \<= 3.9 |`systemctl is-active atomic-openshift-master-api`| >= 3.10 | `oc get pods -n kube-system --no-headers -o=custom-columns=POD:.metadata.name,STATUS:.status.phase &#124; grep -i "master-api" &#124; grep -i "running" &#124;  if [ $( wc -l) -eq 3 ]; then exit 0; else exit 1; fi`

.2+|Master Controllers Service (multi-master) .2+| Check that the Master Controllers Service or pods are active .2+|Masters | \<= 3.9 | `systemctl is-active atomic-openshift-master-controllers`| >= 3.10 | `oc get pods -n kube-system --no-headers -o=custom-columns=POD:.metadata.name,STATUS:.status.phase &#124; grep -i "master-controller" &#124; grep -i "running" &#124; if [ $( wc -l) -eq 3 ]; then exit 0; else exit 1; fi`

.2+|Node Service .2+|Check that the node service is active .2+| All Nodes |  \<= 3.9 |`systemctl is-active atomic-openshift-node`| >= 3.10 | `systemctl is-active atomic-openshift-node`

.2+|Node Storage .2+|Check that the node's local data storage volume is not too full .2+| All Nodes | \<= 3.9 | `echo "$(lvs &#124; awk '/origin/ {print $5}') > 70" &#124; bc`| >= 3.10 | `echo "$(lvs &#124; awk '/origin/ {print $5}') > 70" &#124; bc`

.2+|OpenVSwitch Service .2+|Check that the openvswitch service or pods are active .2+| All Nodes | \<= 3.9 | `systemctl is-active openvswitch`| >= 3.10 | `oc get pods -n openshift-sdn --no-headers -o=custom-columns=POD:.metadata.name,STATUS:.status.phase &#124; grep -i "ovs-" &#124; grep -i "running" &#124; if [ $( wc -l) -eq $(oc get nodes --no-headers &#124; wc -l) ]; then exit 0; else exit 1; fi`

.2+|SDN Service .2+|Check that all the SDN pods are active .2+| All Nodes | \<= 3.9 | NA | >= 3.10 | `oc get pods -n openshift-sdn --no-headers -o=custom-columns=POD:.metadata.name,STATUS:.status.phase &#124; grep -i "sdn-" &#124; grep -i "running" &#124; if [ $( wc -l) -eq $(oc get nodes --no-headers &#124; wc -l) ]; then exit 0; else exit 1; fi`

|===


=== API Endpoints

Many OpenShift components expose HTTP based endpoints for interrogating the health and current operation. The following endpoints should be monitored.

.API Endpoint checks
[width="100%",cols="3,6,10",options="header"]
|=========================================================
|Check Name |Description |Sample Alerting Logic

|OpenShift Master API Server |Check the health of a master API Endpoint| `curl -H "Authorization: Bearer $(oc whoami -t)" https://console.c1-ocp.myorg.com:8443/healthz  &#124; grep ok`

|Router |Check the health of the Router| `curl http://router.default.svc.cluster.local:1936/healthz  &#124; grep 200`

|Registry |Check the health of the Registry| `curl -I https://docker-registry.default.svc.cluster.local:5000/healthz  &#124; grep 200`

|Logging | Check the health of the EFK Logging Stack | Because of the various components and complexities involved, we recommend the link:https://github.com/redhat-cop/openshift-toolkit/blob/master/health_check/elasticsearch-health-check-ocp34.sh[OpenShift Logging health check script].

|Metrics | Check the health of the Metrics Stack | Because of the various components and complexities involved, we recommend the https://github.com/redhat-cop/openshift-toolkit/blob/master/health_check/metrics-health-check.sh[OpenShift Metrics health check script].

|=========================================================

== Ensuring a cluster has adequate capacity

The OpenShift Blog has published an excellent blog series that addresses the issue of cluster capacity management.

link:https://blog.openshift.com/full-cluster-capacity-management-monitoring-openshift/[The first post in this series] addresses the inner workings of Quotas, Requests, and Limits, and how they work together to provide information on cluster capacity.

link:https://blog.openshift.com/full-cluster-part-2-protecting-nodes/[The second post] dives into how OpenShift deals with resource overcomitment. It includes guidance on how to properly protect nodes from issues related to resources strain.

link:https://blog.openshift.com/full-cluster-part-3-capacity-management/[The third post about cluster capacity] really gets into estimating workloads, measuring how accurate your resources estimates are, and finally how to properly size your cluster based on the first two.

== What's Next?

* Monitoring Tooling Implementations (Coming Soon!)
* link:../app_dev/APM_guidance{outfilesuffix}[Application Performance Monitoring Guidance]
