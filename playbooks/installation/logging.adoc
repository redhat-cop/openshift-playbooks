---
---
= Log Management in OpenShift Enterprise

== Application Logs

=== Accessing Container Logs

Because we use Kubernetes as the container orchestrator for OpenShift, the collection of and access to container logs is actually much simpler than most would think. This is because Kubernetes captures all stdout and stderr from every container and writes it to files on the node as json data within the container's data directory (i.e. `/var/lib/docker/<container-id>/<container-id>-json.log`). Kubernetes then creates a symbolic link to that logfile in /var/log/containers/, the name of which contains metadata about the continer such as namespace, container and pod ids. For example:

----
synthetic-logger-0.25lps-pod_default_synth-lgr-997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b.log
->
/var/lib/docker/containers/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b/997599971ee6366d4a5920d25b79286ad45ff37a74494f262e3bc98d909d0a7b-json.log
----

Awesome! No agents or container customization needed. We just have our application use a stdout/stderr logger (i.e. Console Logger in JBoss) and Kubernetes takes care of the rest.

=== Log Aggregation

Since we already have the container logs available on the Node's file system, we can concentrate on doing something useful with them.

==== Simple Aggregation with Syslog Forwarders

If we just need to collect the raw data, then the centralization process is very simple. We can just point syslog at the directory containing log files and have it forward data on to a link:http://www.itzgeek.com/how-tos/linux/centos-how-tos/setup-syslog-server-on-centos-7-rhel-7.html[central logging server].

.Feedback or Contribution Needed
****
Need some examples of forwarding OpenShift logs using rsyslog.
****

==== Centralizing Logs with Fluentd

The OpenShift 3.0 Documentation provides a way to link:https://docs.openshift.com/enterprise/3.0/admin_guide/aggregate_logging.html[use Fluentd to capture and centralize container logs]. This implementation is fairly limiting though as it doesn't fully parse the log files and capture metadata like namespaces, pods names, etc.

==== Full Metadata Supported Log Aggregation with Fluentd

If we want to collect application metadata so that we can do things like filter logging views based on the application or project, we need to install some additional Fluentd plugins to make our aggregation agent more Kubernetes and Docker aware. Unfortunately this is more complicated at the moment (with OSE 3.0) because Red Hat does not ship fluentd or any of its plugins, so there are no RPMs or installation channels to facilitate installation in an Enterprise Environment.

Here is a guide that walks through installation of fluentd and required plugins using as RubyGems.

link:./logging_with_fluentd.adoc[Using Fluentd to Centralize Container Logs]

== System Logs

.Feedback or Contribution Needed
****
Need to add discussions about collecting systemlogs for OpenShift
****
